{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Collaborative filtering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from pyspark.sql import SparkSession\r\n",
    "spark = SparkSession.builder.appName(\"Collaborative filtering\").getOrCreate()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "moviesDF = spark.read.options(inferSchema=True, header=True).csv(\r\n",
    "    \"data/collaborative_filtering/movies.csv\")\r\n",
    "ratingsDF = spark.read.options(inferSchema=True, header=True).csv(\r\n",
    "    \"data/collaborative_filtering/ratings.csv\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "moviesDF.printSchema()\r\n",
    "ratingsDF.printSchema()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ratings = ratingsDF.join(moviesDF, \"movieId\", \"left\")\r\n",
    "train, test = ratings.randomSplit([0.8, 0.2])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train.count(), test.count()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(80770, 20066)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from pyspark.ml.recommendation import ALS\r\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\r\n",
    "          nonnegative=True, implicitPrefs=False, coldStartStrategy=\"drop\",)\r\n",
    "\r\n",
    "# coldStartStrategy = \"drop\" --> drop the value of user who have not calificated\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\r\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "param_grid = (\r\n",
    "    ParamGridBuilder()\r\n",
    "    .addGrid(als.rank, [10, 50, 100, 150])\r\n",
    "    .addGrid(als.regParam, [0.1, 0.5, 0.1, 0.15])\r\n",
    ").build()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "evaluator = (\r\n",
    "    RegressionEvaluator(\r\n",
    "        metricName=\"rmse\",\r\n",
    "        labelCol=\"rating\",\r\n",
    "        predictionCol=\"prediction\"\r\n",
    "    )\r\n",
    ")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model = cv.fit(train)\r\n",
    "best_model = model.bestModel\r\n",
    "test_predictions = best_model.transform(test)\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'RegressionEvaluator' object is not callable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-dbb4cd1a1489>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mRMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRMSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'RegressionEvaluator' object is not callable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "RMSE = evaluator.evaluate(test_predictions)\r\n",
    "print(RMSE)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8696997246369751\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "recommendations = best_model.recommendForAllUsers(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "recommendations.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[{89904, 4.514392...|\n",
      "|   463|[{60943, 4.834961...|\n",
      "|   496|[{8477, 4.5131974...|\n",
      "|   148|[{89904, 4.517269...|\n",
      "|   540|[{60943, 5.131281...|\n",
      "|   392|[{8477, 5.032757}...|\n",
      "|   243|[{8477, 5.4483294...|\n",
      "|    31|[{134796, 4.94217...|\n",
      "|   516|[{6201, 4.6313033...|\n",
      "|   580|[{60943, 4.756531...|\n",
      "|   251|[{132333, 5.30952...|\n",
      "|   451|[{132333, 5.12794...|\n",
      "|    85|[{1140, 4.8483987...|\n",
      "|   137|[{6650, 4.800531}...|\n",
      "|    65|[{8477, 4.690697}...|\n",
      "|   458|[{42730, 5.280007...|\n",
      "|   481|[{3451, 4.0450783...|\n",
      "|    53|[{78836, 6.262577...|\n",
      "|   255|[{1194, 4.087688}...|\n",
      "|   588|[{132333, 4.33673...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}